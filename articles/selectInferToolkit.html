<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Using the selectInferToolkit Package • selectInferToolkit</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Using the selectInferToolkit Package">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">selectInferToolkit</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/selectInferToolkit.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Using the selectInferToolkit Package</h1>
                        <h4 data-toc-skip class="author">Jinal Shah
&amp; Ryan A Peterson</h4>
            
            <h4 data-toc-skip class="date">2025-11-15</h4>
      

      <div class="d-none name"><code>selectInferToolkit.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>In the era of big data and complex regression problems, researchers
often employ model selection procedures like step wise regression or
penalized methods (e.g., lasso) to identify important variables.
However, classical statistical inference assumes the model was chosen a
prior—independent of the data. When this assumption is violated,
standard statistical tests and confidence intervals can become overly
optimistic, leading to unreliable conclusions.
<code>selectInferToolkit</code> aims to provide a user-friendly
framework in R to facilitate post-selection inferential methods and
model selection methods.</p>
</div>
<div class="section level2">
<h2 id="methods">Methods<a class="anchor" aria-label="anchor" href="#methods"></a>
</h2>
<div class="section level3">
<h3 id="model-selection-methods">Model selection methods<a class="anchor" aria-label="anchor" href="#model-selection-methods"></a>
</h3>
<p>For the conventional stepwise selection algorithms, we employed
“forward”, “backward” and “bidirectional” (also known as “bidirectional
elimination”) methods. Forward selection begins with an empty model and
progressively adds the most significant predictors. The process
continues until no further statistically significant improvements are
observed by some predefined criterion. Backward selection starts with a
full model that includes all predictors and systematically removes the
least significant predictors. The process stops when all remaining
predictors are statistically significant by some predefined criterion.
The stepwise selection approach allows the model to add variables
(forward selection) and remove variables (backward elimination) at each
step, based on specific criteria to determine the best-fitting model. We
used both the Akaike Information Criterion (AIC) and Bayesian
Information Criterion (BIC) for model selection with stepwise
regression.</p>
<p>Penalized regression methods aim to minimize the log-likelihood
function under a constraint that penalizes large absolute values of
coefficients and/or model complexity. The L1 penalty used in lasso (the
sum of absolute values of regression coefficients multiplied by the
penalty factor,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>),
enables simultaneous variable selection and coefficient estimation,
making it particularly useful for high-dimensional settings. However,
one limitation of lasso is that, in the presence of multicollinearity,
it tends to select one variable from a group of highly correlated
variables and exclude the others. Additionally, when there are highly
correlated variables, the estimation can become unstable, and lasso may
not perform as well as Ridge regression which uses L2 penalty (the sum
of the squares of the regression coefficients multiplied by their
respective penalty factors). The elastic net combines both L1 and L2
penalties, introducing an additional penalty factor to provide more
stability in model estimation and allowing for more robust variable
selection, particularly in the presence of multicollinearity. Finally,
the minimax concave penalty (MCP) is an alternative method that produces
less biased regression coefficients than sparse models. MCP includes an
additional tuning parameter,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>γ</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math>,
which controls the concavity of the penalty (i.e., how quickly the
penalty decreases). Many additional forms of penalized regression have
been proposed, we focus on this set in our package.</p>
</div>
<div class="section level3">
<h3 id="target-of-inferencehandling-non-selections">Target of Inference/Handling Non-selections<a class="anchor" aria-label="anchor" href="#target-of-inferencehandling-non-selections"></a>
</h3>
<p>(under construction)</p>
</div>
<div class="section level3">
<h3 id="post-selection-inference-methods">Post-selection inference methods<a class="anchor" aria-label="anchor" href="#post-selection-inference-methods"></a>
</h3>
<div class="section level4">
<h4 id="upsi">UPSI<a class="anchor" aria-label="anchor" href="#upsi"></a>
</h4>
<p>The first approach involves ignoring the model selection process (no
matter which model selection method is used) when making inferences on
the final selected model. The ‘unadjusted post-selection inference’
(UPSI) approach, sometimes referred to as two-stage or hybrid solution
for inference post-regularization, is to first use a stepwise/penalized
model to select variables, then fit an OLS model with the selected
variables to obtain standard errors and CIs. While, this is invalid in
most scenarios, recent research (Zhao et el.) suggests that, under
certain conditions—specifically, when the sample size is large, the true
model is sparse, and the predictors have low mutual correlations—the set
of variables selected by the lasso will converge to a deterministic set
with high probability. This we provide this method to standardize the
implementation in practice.</p>
</div>
<div class="section level4">
<h4 id="bootstrap">Bootstrap<a class="anchor" aria-label="anchor" href="#bootstrap"></a>
</h4>
<p>The package provides two different ways to implement non-parametric
bootstrap based on target of inference.</p>
<p><strong>Bootstrap CIs for the Selected Model</strong></p>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
be a model selection procedure yielding the prime model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>M</mi><mo accent="true">̂</mo></mover><mi>s</mi></msub><mo>⊂</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>p</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\hat{M}_s \subset \{1, \dots, p\}</annotation></semantics></math>.<br>
We estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo>∣</mo><msub><mover><mi>M</mi><mo accent="true">̂</mo></mover><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">\hat{\beta} \mid \hat{M}_s</annotation></semantics></math>,
i.e., coefficients conditional on the selected model.<br>
For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>∈</mo><msub><mover><mi>M</mi><mo accent="true">̂</mo></mover><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">j \in \hat{M}_s</annotation></semantics></math>,
the coefficient is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mi>j</mi></msub><annotation encoding="application/x-tex">\hat{\beta}_j</annotation></semantics></math>;
otherwise, NA.</p>
<pre><code>*Procedure:*
  - For each bootstrap iteration:  
    1. Resample data with replacement.  
    2. Apply \( s \) to the resample.  
    3. Record coefficients for \( j \in \hat{M}_s \); set to zero if missing.  
    4. Compute CIs from bootstrap quantiles.</code></pre>
<p><strong>Bootstrap CIs for All Variables</strong></p>
<p>If inference targets all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
variables:</p>
<ol style="list-style-type: decimal">
<li>
<em>Treating non-selections as confident nulls:</em>
<ol style="list-style-type: decimal">
<li>Resample data with replacement.<br>
</li>
<li>Apply
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
to the resample.<br>
</li>
<li>et coefficients of non-selections to zero.<br>
</li>
</ol>
</li>
<li>
<em>Treating non-selections as uncertain nulls:</em>
<ol style="list-style-type: decimal">
<li>Resample data with replacement.<br>
</li>
<li>Apply
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
to the resample.<br>
</li>
<li>After selection, regress residuals on each non-selected variable
individually.</li>
</ol>
</li>
</ol>
<p>Both yield bootstrap distributions for all variables, enabling CI
calculation.</p>
<p>There is an option to refit OLS within each iteration (essentially a
debiased bootstrap approach).</p>
</div>
<div class="section level4">
<h4 id="selective-inference">Selective Inference<a class="anchor" aria-label="anchor" href="#selective-inference"></a>
</h4>
<p>Selective inference is a post-selection inferential technique that
focuses on making valid inferences on coefficients by conditioning on
the model selection process itself and implemented in
<code>selectiveInference</code> R package. Currently, they’re available
after using forward step wise selection or lasso regression to select
the model. For more details on this method, consult the documentation
for the <code>selectiveInference</code> R package or <a href="https://www.pnas.org/doi/10.1073/pnas.1507583112" class="external-link">its associated
paper</a>.</p>
<p>The rest of the document goes through several use cases of the
package on different data sets.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="general-workflow-for-using-pacakge">General workflow for using pacakge<a class="anchor" aria-label="anchor" href="#general-workflow-for-using-pacakge"></a>
</h2>
<!-- In order to first use the model selection procedure, user can use either `step_ic()` function or `pen_cv()` function to fit either the stepwise or penalized models respectively. Specifically, there are three option to choose for direction ("backward", "forward" or "both" (default)) and they have two option for penalty (either "AIC" or "BIC"), Similarly, for penalized models, one needs to use the pen_cv function with either "lasso" or "MCP" option for penalty. Users can also choose to extract the coefficients associated with either "lambda.min" or "lambda.1se".  -->
<!-- Both `step_ic()` and  `pen_cv()` will produce `selector` class object which can then be passed to `infer()` function to make post-selection inference. User can choose one of three `method` options:  "hybrid", "selectiveinf" or "boot" for performing post-selection inference using either "Hybrid", "selective inference" or "boostrap" methods respectively.  -->
<p>TBD</p>
</div>
<div class="section level2">
<h2 id="use-case-hers-data">Use case: HERS data<a class="anchor" aria-label="anchor" href="#use-case-hers-data"></a>
</h2>
<p>TBD. For now please see the package readme for a use-case.</p>
<!-- ## 3.1 Dataset description -->
<!-- To illustrate a realistic example, we use the data from the Heart and Estrogen/Progestin Replacement Study (HERS). HERS was a randomized, double-blind, placebo-controlled secondary prevention trial conducted between January 1993 and September 1994 in outpatient and community settings at 20 U.S. clinical centers. In this trial, 2,763 postmenopausal women with established coronary heart disease (CHD) were randomized to receive either a placebo or estrogen plus progestin therapy to assess whether treatment influenced the risk of future CHD events. In our guiding application, we aim to model the continuous outcome of High-Density Lipoprotein (HDL) one year after treatment, based on baseline covariates. A total of 25 baseline characteristics are available to predict HDL levels one-year post-treatment for 2,571 observations with complete covariate data. Covariates of interest include treatment group, demographic variables, lifestyle factors, health status/activity levels, comorbidities, medications, baseline physical measurements, and baseline lab values. -->
<!-- First let's look at the data a litte: -->
<!-- ```{r} -->
<!-- data("hers") -->
<!-- summary(hers) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- y= hers$hdl1 -->
<!-- x <- hers %>% dplyr::select(-hdl1) -->
<!-- ``` -->
<!-- ## 3.2 Performing model selection -->
<!-- ### 3.2.1 Perfoming Stepwsie AIC model selection  -->
<!-- ```{r} -->
<!-- aic_model=step_ic (x=x,y=y,std = TRUE, penalty = "AIC", direction = "both") -->
<!-- ``` -->
<!-- ### 3.2.1 Perfoming penalized model selection  -->
<!-- ```{r} -->
<!-- lassomin_model =pen_cv (x=x,y=y,penalty= "lasso",lambda="lambda.min",std=TRUE) -->
<!-- ``` -->
<!-- ## 3.3  Perfoming post-selection inference  -->
<!-- ### 3.3.1 Hybrid method  -->
<!-- ```{r} -->
<!-- aic_hybrid =infer(aic_model,  method = "hybrid", nonselection = "ignored") -->
<!-- ``` -->
<!-- ```{r eval=FALSE} -->
<!-- aic_model_fw= step_ic (x=x,y=y,std = T, penalty = "AIC", direction = "forward") -->
<!-- #View(aic_model_fw[["beta"]]) -->
<!-- fit_aic__fwd_hybrid <- infer(aic_model_fw , method = "hybrid") -->
<!-- tidy(fit_aic__fwd_hybrid ) -->
<!-- fit_aic_SI_wfd <- infer(aic_model_fw, method = "selectiveinf") -->
<!-- tidy(fit_aic_SI_wfd ) -->
<!-- ``` -->
<!-- ```{r eval=FALSE} -->
<!-- ## 3.2.1 Performing Stepwsie AIC model selection  -->
<!-- lassomin_model =pen_cv (x=x,y=y,penalty= "lasso",lambda="lambda.min",std=TRUE) -->
<!-- lassomin_hybrid =infer(lassomin_model,  method = "hybrid", nonselection = "ignored") -->
<!-- lassomin_selc=infer(lassomin_model,  method = "selectiveinf", nonselection = "ignored") -->
<!-- lassomin_boot=infer(lassomin_model,  method = "boot", nonselection = "ignored", B=5) -->
<!-- tidy(lassomin_hybrid) -->
<!-- tidy(lassomin_selc) -->
<!-- tidy(lassomin_boot) -->
<!-- ``` -->
<!-- #### Bootstrapping  -->
<!-- ##### Ignored non-selections -->
<!-- ```{r AIC bootstrap, eval=FALSE} -->
<!-- set.seed(1) -->
<!-- fit_aic_boot <- infer(fit_aic, method = "boot", B = 100)  -->
<!-- fit_aic_boot -->
<!-- tidy(fit_aic_boot)  -->
<!-- ``` -->
<!-- Similar to the selective inference result, none of our 3 effects remain significant after adjusting for uncertainty in the model selection process. However, our intervals are finite, which is an improvement.  -->
<!-- ##### Confident null non-selections -->
<!-- In this setting, we are interested in making inferences for all variables, including those not selected by the prime model using full data (i.e., using `step_ic()` or `pen_cv()` on full dataset). Compared to the previous approach, the primary difference here is that, for each bootstrap iteration, after applying the same model selection method to a bootstrap sample, we retain the coefficients for *all variables, regardless of whether they were included in the prime model or not*. For any variable not selected in a given bootstrap sample, its coefficient is set to zero. This process produces a bootstrap distribution for all $p$ variables, allowing us to calculate CIs by using the quantiles of these distributions.  -->
<!-- ```{r AIC bootstrap 2,eval=FALSE} -->
<!-- set.seed(1) -->
<!-- fit_aic_boot <- infer(fit_aic, method = "boot", B = 100, nonselection = "confident_nulls")  -->
<!-- fit_aic_boot -->
<!-- tidy(fit_aic_boot)  -->
<!-- ``` -->
<!-- Here again we notice that among all the variables, only `wt` and `cycl` variable is selected in more than 50% of the bootstrap samples. However,  here again none of our effects remain significant after adjusting for uncertainty in the model selection process.  -->
<!-- ##### Uncertain null non-selections -->
<!-- In this setting, we are also interested in making inferences for all variables, including those not selected by the prime model using full data (i.e., using step_ic() or pen_cv() on full data set). Compared to the previous approach of treating non-selections as `confident null`, the primary difference here is that, for each bootstrap iteration, in order to get coefficient for all variables, we also get the coefficient for non-selections instead of setting them to zero. That is after applying the same selection method to a bootstrap sample, we retain the coefficients for all variables, regardless of whether they were included in the prime model or not. But for any variable not selected in a given bootstrap sample, we regress the model residuals on the each non-selected variables separately to get the beta estimates for non-selections. By doing so, we're trying to explain the residual variance by variables that were not selected by model selection method. This process will again produces a bootstrap distribution for all $p$ variables, allowing us to calculate CIs by using the quantiles of these distributions.  -->
<!-- ### BIC vs AIC -->
<!-- No matter how we look, we find our selections are no longer significant after adjusting for the selective inference process. What gives? It may be that AIC is not as conducive to post-selection inference as a more conservative criterion such as BIC. Let's investigate.  -->
<!-- ```{r eval=FALSE} -->
<!-- fit_bic <- step_ic(y = mtcars$mpg, x=X, penalty = "BIC") -->
<!-- fit_bic  -->
<!-- tidy(infer(fit_bic, method = "hybrid")) -->
<!-- ``` -->
<!-- As expected with BIC, we get fewer variables, specifically BIC does not select `hp`. And as before, a hybrid method ignoring non-selections finds that both `cyl` and `wt` are significant as shown above.  -->
<!-- *Selective inference* -->
<!-- ```{r eval=FALSE} -->
<!-- fit_bic_SI <- infer(fit_bic, method = "selectiveinf") -->
<!-- fit_bic_SI -->
<!-- tidy(fit_bic_SI) -->
<!-- ``` -->
<!-- Selective inference gives wider confidence interval and once selection procedure is taken into account, both selected variables are no longer significant.  -->
<!-- *Bootstrapping* -->
<!-- ```{r eval=FALSE} -->
<!-- set.seed(1) -->
<!-- fit_bic_boot <- infer(fit_bic, method = "boot", B = 100)  -->
<!-- tidy(fit_bic_boot) -->
<!-- ``` -->
<!-- Again, with bootstrap with see that while `cyl` is only selected 42% of the times compared to `wt` which is selected 87% of the time. However based on bootstrapped CI, neither of them are significant.  -->
<!-- We find that AIC nor BIC are able to recover any significant effects on their own, regardless of the method used for post-selection inference.   -->
<!-- ### collating methods  -->
<!-- Lastly, one way to compare the precision of our model selection/inference method is by looking at the length of confidence intervals. That can be done with `ciratio` function which returns a list with three cross tables. One for average CI length across all variables, second one for median CI length across all variables and lastly number of significant discoveries across all models.  -->
<!-- ```{r eval=FALSE} -->
<!-- set.seed(1234) -->
<!-- precision= ciratio(X, y = mtcars$mpg,B=50, nonselection="ignored") -->
<!-- precision[["avg_ci_ln"]] -->
<!-- ``` -->
<!-- We see that in general, the selective inference method gives wider CI compared to hybrid or bootstrap for given model selection procedure. Boostrap gives wider CI compared to hybrid method for full model and stepwise methods but it is more precise on average compared to hybrid for penalized methods. We can also look at average of medianc CI for each variable as follow: -->
<!-- ```{r eval=FALSE} -->
<!-- precision[["med_ci_ln"]] -->
<!-- ``` -->
<!-- While, we see that medican CI lenght for given model is slightly lower comapred to mean CI length, we see similar trend when comparing different methods as above.  -->
<!-- ```{r eval=FALSE} -->
<!-- precision[["no_sign_disc"]] -->
<!-- ``` -->
<!-- We see that in general with bootstrap approach, we have more discovires compared to hybrid and selective inference.  -->
<!-- ### BIC vs AIC -->
<!-- No matter how we look, we find our selections are no longer significant after adjusting for the selective inference process. What gives? It may be that AIC is not as conducive to post-selection inference as a more conservative criterion such as BIC. Let's investigate.  -->
<!-- ```{r eval=FALSE} -->
<!-- fit_bic <- step_ic(y = mtcars$mpg, x=X, penalty = "BIC") -->
<!-- fit_bic  -->
<!-- tidy(infer(fit_bic, method = "hybrid")) -->
<!-- ``` -->
<!-- As expected with BIC, we get fewer variables, specifically BIC does not select `hp`. And as before, a hybrid method ignoring non-selections finds that both `cyl` and `wt` are significant as shown above.  -->
<!-- *Selective inference* -->
<!-- ```{r eval=FALSE} -->
<!-- fit_bic_SI <- infer(fit_bic, method = "selectiveinf") -->
<!-- fit_bic_SI -->
<!-- tidy(fit_bic_SI) -->
<!-- ``` -->
<!-- Selective inference gives wider confidence interval and once selection procedure is taken into account, both selected variables are no longer significant.  -->
<!-- *Bootstrapping* -->
<!-- ```{r eval=FALSE} -->
<!-- set.seed(1) -->
<!-- fit_bic_boot <- infer(fit_bic, method = "boot", B = 100)  -->
<!-- tidy(fit_bic_boot) -->
<!-- ``` -->
<!-- Again, with bootstrap with see that while `cyl` is only selected 42% of the times compared to `wt` which is selected 87% of the time. However based on bootstrapped CI, neither of them are significant.  -->
<!-- We find that AIC nor BIC are able to recover any significant effects on their own, regardless of the method used for post-selection inference.   -->
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Ryan Peterson.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>

---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%", 
  error = TRUE
)
```

# practicalPSI

<!-- badges: start -->
<!-- badges: end -->

The goal of practicalPSI is to facilitate post-selection inferential methods in R in user-friendly ways. 

## Installation

You can install the development version of practicalPSI like so:

```{r, eval = FALSE}
devtools::install_github("petersonR/practicalPSI")
```

## Example

Let's say you are wanting to predict gas mileage based on all variables in the `mtcars` data set. 

```{r example}
library(practicalPSI)

data("mtcars")

fit_full <- lm(mpg ~ ., data = mtcars)
summary(fit_full)
```

Hmm, $R^2$ is high but nothing is "significant". What is going on? The model is probably over-specified. Let's use `practicalPSI` to narrow in on what we think the most important factors are. The `step_ic` function can do forwards and backwards selection via AIC by default. 

### `step_ic`


```{r}
X <- model.matrix(fit_full)[,-1]
head(X)

fit_aic <- step_ic(y = mtcars$mpg, x = X, std = TRUE ) # does not work
fit_aic <- step_ic(y = mtcars$mpg, x = X) 
fit_aic
```

AIC selects `wt`, `qsec`, and `am`. But where are the p-values?! This is where post-selection inference comes in; p-values that do not adjust for the selective process are not valid (they will be too small!). We refer to this as a "hybrid" method where selection is performed and ordinary least squares theory is used for inference. 

```{r}
fit_aic_hybrid <- infer(fit_aic, method = "hybrid")
tidy(fit_aic_hybrid)
```

What if we wanted to adjust for the selective process? Here using `selectiveInference`. 

```{r}
fit_aic_SI <- infer(fit_aic, method = "selectiveinf")
fit_aic_SI # both is possible for this? 
tidy(fit_aic_SI) # why is the selection different? 
```

What about bootstrapping? 

```{r}
set.seed(1)
fit_aic_boot <- infer(fit_aic, method = "boot", B = 100) # needs print method
tidy(fit_aic_boot) # needs tidy method
fit_aic_boot$model # probably don't report median_p.value, something else instead?
```

In either case, we find the selections no longer significant after adjusting for the selective inference process. What gives? 

```{r}
fit_bic <- step_ic(y = mtcars$mpg, x=X, penalty = "BIC")
fit_bic 
tidy(infer(fit_bic)) # should be same as fit_aic_hybrid, same model
```

Selective inference: 

```{r}
fit_bic_SI <- infer(fit_bic, method = "selectiveinf")
fit_bic_SI # Much smaller intervals

tidy(fit_bic_SI)
```

Whoa! Now we have gear pop out as significant! But wait, "gear" is not in `fit_bic` as selection. what gives? 

What about bootstrapping? 

```{r}
set.seed(1)
fit_bic_boot <- infer(fit_bic, method = "boot", B = 100) 
fit_bic_boot$model 
```



### `pen_cv`


```{r}
set.seed(12)
fit_lso <- pen_cv(y = mtcars$mpg, x = X) # does not work
fit_lso <- pen_cv(y = mtcars$mpg, x = data.frame(X), std=FALSE) 
fit_lso # nothing selected? 

infer(fit_lso) # does not work

set.seed(12)
fit_cv <- cv.ncvreg(X, y = mtcars$mpg)
summary(fit_cv) # something not right here

```

